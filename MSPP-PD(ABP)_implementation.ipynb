{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gb\n",
    "import math\n",
    "\n",
    "from gurobipy import GRB\n",
    "from utils import file_reader as fr\n",
    "from utils import data_generator as dg\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First MSSP-PD(ABP) example\n",
    "\n",
    "In MSPP-PD we want to minimize not only distances, but also the path conflict between different agents and since \"path conflict\" can take on different nuances we can define different versions of the MSPP-PD.  \n",
    "\n",
    "For example it can be assessed as it pertains to agents' paths when they utilize the same arcs, the same nodes, or both. Furthermore also the degree of penalty assessed for a given (node or arc) conflict may vary. Conflic may be of concern:\n",
    "\n",
    "- simply for occurring (binary metric);\n",
    "- for occurring in relation to the number of agents for a given path conflict (linear metric), or;\n",
    "- for occurring in relation to the number of potential interactions between agents for a given conflict (quadratic metric).  \n",
    "\n",
    "Each possible combination will result in a different version of the MSPP-PD.\n",
    "\n",
    "The one we will focus on this notebook is the one that penalize agent's path conflict on the network arcs in a binary fashion (arc binary penalties (__ABP__)). This means that for instance, if $2,...,n$ agents use arc $(i,j)$ on their respective sources-terminus paths, an arc binary penalty equal to 1 will be incurred.  \n",
    "\n",
    "In the following we'll formulate and solve a MSPP-PD(ABP)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "\n",
    "In this section we read the file containing the netwoork instance that we'll use to solve the MSPP.  \n",
    "The instance is the same as in the case of the MSPP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>it1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     it1\n",
       "0 5  3.0\n",
       "  6  1.0\n",
       "1 5  1.0\n",
       "  6  1.0\n",
       "  7  1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_5x5_df = fr.read_networks_csv(\"data/d_it_ij_5x5_1it.csv\",\n",
    "                                        along=\"cols\")\n",
    "\n",
    "# show some arcs with related weights of the network\n",
    "synthetic_5x5_df.T.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage data\n",
    "\n",
    "In this section we define the variables that we'll use to formulate and solve the MSPP-PD(ABP) problem starting from the dataframe containing the network instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes in the network\n",
    "nodes = dg.get_nodes(synthetic_5x5_df)\n",
    "\n",
    "\n",
    "# weighted arcs in the network\n",
    "# the weight of each arc represents the ditance between 2 nodes\n",
    "w_arcs = [dg.WArc(i, j, synthetic_5x5_df.loc[\"it1\", (i, j)], idx)\n",
    "          for idx, (i, j) in enumerate(synthetic_5x5_df.columns)]\n",
    "\n",
    "\n",
    "# agets that has to be routed\n",
    "agents_sources = [0, 2, 3, 4]\n",
    "agents_terminus = [20, 22, 23, 24]\n",
    "agents_idxs = [0, 1, 2, 3]\n",
    "agents = [dg.Agent(s, t, idx) for s, t, idx in zip(\n",
    "    agents_sources, agents_terminus, agents_idxs)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem formulation and solution\n",
    "\n",
    "In this section we formulate and solve the MSPP-PD(ABP) problem using Gurobi.  \n",
    "The formulations follows the one reported in section 2.3 of the paper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-12-10\n"
     ]
    }
   ],
   "source": [
    "MSPP_PD_ABP_pb = gb.Model(\"First MSPP_PD_ABP_pb\")\n",
    "# MSPP_PD_ABP_pb.setParam(\"OutputFlag\", 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define decision variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_var_shape = len(w_arcs), len(agents)\n",
    "Psi_var_shape = len(w_arcs)\n",
    "\n",
    "X = MSPP_PD_ABP_pb.addMVar(X_var_shape,\n",
    "                           vtype=GRB.BINARY,  # 5) Binary constraints\n",
    "                           name=\"X\")\n",
    "\n",
    "Psi = MSPP_PD_ABP_pb.addMVar(Psi_var_shape,\n",
    "                             vtype=GRB.BINARY,  # 8) Binary constraints\n",
    "                             name=\"Psi\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the 2 objective functions:\n",
    "- one that penalize solutions that makes agents travel higher distances\n",
    "- one that penalize solutions that makes agents traverse the same arcs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:3, 6) Objective functions\n",
    "distance_obj = gb.quicksum(\n",
    "    arc.w * X[arc.idx, agent.idx]\n",
    "    for arc in w_arcs for agent in agents\n",
    ")\n",
    "penalty_obj = gb.quicksum(\n",
    "    Psi[arc.idx] for arc in w_arcs\n",
    ")\n",
    "\n",
    "# as result objective will be: f(X, Psi) = 0.5*distance_obj(X) + 0.5*penalty_obj(Psi)\n",
    "MSPP_PD_ABP_pb.setObjectiveN(distance_obj, index=0, weight=0.5,\n",
    "                             name=\"Distance\")\n",
    "MSPP_PD_ABP_pb.setObjectiveN(penalty_obj, index=1, weight=0.5,\n",
    "                             name=\"Penalty\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Flow constraints\n",
    "\n",
    "def compute_flow(X, node, w_arcs, agent):\n",
    "    \"\"\"Compute the flow in a node of a network for a given agent that traverse it\n",
    "\n",
    "    Args:\n",
    "        X (gb.MVar): X decision variables of a MSPP or MSPP-PD problem\n",
    "        node (int): the node on which compute the flow\n",
    "        w_arcs (list): list of WArc that compose the network\n",
    "        agent (Agent): the agent for which to calculate the flow\n",
    "\n",
    "    Returns:\n",
    "        gb.MLinExpr: linear matrix expression that represent the flow for the agent in the node\n",
    "    \"\"\"\n",
    "\n",
    "    flow_out = gb.quicksum(\n",
    "        X[arc.idx, agent.idx]\n",
    "        for arc in w_arcs if arc.i == node\n",
    "    )\n",
    "    flow_in = gb.quicksum(\n",
    "        X[arc.idx, agent.idx]\n",
    "        for arc in w_arcs if arc.j == node\n",
    "    )\n",
    "    return flow_out - flow_in\n",
    "\n",
    "\n",
    "for agent in agents:\n",
    "    for node in nodes:\n",
    "        if node == agent.source:\n",
    "            MSPP_PD_ABP_pb.addConstr(compute_flow(X, node, w_arcs, agent) == 1)\n",
    "        elif node == agent.terminus:\n",
    "            MSPP_PD_ABP_pb.addConstr(\n",
    "                compute_flow(X, node, w_arcs, agent) == -1)\n",
    "        else:\n",
    "            MSPP_PD_ABP_pb.addConstr(compute_flow(X, node, w_arcs, agent) == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Binary penalization constraints\n",
    "\n",
    "for arc in w_arcs:\n",
    "    MSPP_PD_ABP_pb.addConstr(\n",
    "        1/len(agents) *\n",
    "        (gb.quicksum(X[arc.idx, agent.idx] for agent in agents) - 1)\n",
    "        <= Psi[arc.idx]\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve the problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 10.0.0 build v10.0.0rc2 (linux64)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-7200U CPU @ 2.50GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 2 physical cores, 2 logical processors, using up to 2 threads\n",
      "\n",
      "Optimize a model with 152 rows, 260 columns and 676 nonzeros\n",
      "Model fingerprint: 0x3a72c5db\n",
      "Variable types: 0 continuous, 260 integer (260 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-01, 1e+00]\n",
      "  Objective range  [1e+00, 3e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [2e-01, 1e+00]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Multi-objectives: starting optimization with 2 objectives (1 combined) ...\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Multi-objectives: optimize objective 1 (weighted) ...\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Optimize a model with 152 rows, 260 columns and 676 nonzeros\n",
      "Model fingerprint: 0x090b122e\n",
      "Variable types: 0 continuous, 260 integer (260 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-01, 1e+00]\n",
      "  Objective range  [5e-01, 2e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [2e-01, 1e+00]\n",
      "Found heuristic solution: objective 12.0000000\n",
      "Presolve removed 114 rows and 192 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 38 rows, 68 columns, 163 nonzeros\n",
      "Variable types: 0 continuous, 68 integer (68 binary)\n",
      "Found heuristic solution: objective 9.3000000\n",
      "\n",
      "Root relaxation: objective 8.500000e+00, 12 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0       8.5000000    8.50000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (12 simplex iterations) in 0.13 seconds (0.00 work units)\n",
      "Thread count was 2 (of 2 available processors)\n",
      "\n",
      "Solution count 3: 8.5 9.3 12 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.500000000000e+00, best bound 8.500000000000e+00, gap 0.0000%\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Multi-objectives: solved in 0.19 seconds (0.00 work units), solution count 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# min( f(X, Psi) )\n",
    "MSPP_PD_ABP_pb.optimize()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report results\n",
    "\n",
    "In this section we report the results that we've obtained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of the optimization is:\n",
      "optimal\n"
     ]
    }
   ],
   "source": [
    "print(\"Result of the optimization is:\")\n",
    "if MSPP_PD_ABP_pb.Status == 2:\n",
    "    print(\"optimal\")\n",
    "elif MSPP_PD_ABP_pb.Status == 3:\n",
    "    print(\"infeasible\")\n",
    "elif MSPP_PD_ABP_pb.Status == 5:\n",
    "    print(\"unbounded\")\n",
    "else:\n",
    "    print(\"Some other return status\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimization founds 3 solutions:\n",
      "\n",
      "Solution 0: Distance=16.0 | Penalty=1.0 | Weighted Total=8.5\n",
      "Agent 0 will follow the path:\n",
      "0->6\t6->12\t12->16\t16->20\t\n",
      "Agent 1 will follow the path:\n",
      "2->7\t7->12\t12->18\t18->22\t\n",
      "Agent 2 will follow the path:\n",
      "3->7\t7->12\t12->17\t17->23\t\n",
      "Agent 3 will follow the path:\n",
      "4->8\t8->14\t14->18\t18->24\t\n",
      "\n",
      "Solution 1: Distance=18.6 | Penalty=0.0 | Weighted Total=9.3\n",
      "Agent 0 will follow the path:\n",
      "0->6\t6->12\t12->16\t16->20\t\n",
      "Agent 1 will follow the path:\n",
      "2->7\t7->12\t12->18\t18->22\t\n",
      "Agent 2 will follow the path:\n",
      "3->7\t7->12\t12->17\t17->23\t\n",
      "Agent 3 will follow the path:\n",
      "4->8\t8->14\t14->18\t18->24\t\n",
      "\n",
      "Solution 2: Distance=24.0 | Penalty=0.0 | Weighted Total=12.0\n",
      "Agent 0 will follow the path:\n",
      "0->6\t6->12\t12->16\t16->20\t\n",
      "Agent 1 will follow the path:\n",
      "2->7\t7->12\t12->18\t18->22\t\n",
      "Agent 2 will follow the path:\n",
      "3->7\t7->12\t12->17\t17->23\t\n",
      "Agent 3 will follow the path:\n",
      "4->8\t8->14\t14->18\t18->24\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_objectives = MSPP_PD_ABP_pb.NumObj\n",
    "n_solutions = MSPP_PD_ABP_pb.SolCount\n",
    "\n",
    "print(f\"The optimization founds {n_solutions} solutions:\")\n",
    "print()\n",
    "# Notice that are not all optimal:\n",
    "# \"By default, the Gurobi MIP solver will try to find one proven optimal solution to your model.\n",
    "# It will typically find multiple sub-optimal solutions along the way, which can be retrieved later\".\n",
    "# From: https://www.gurobi.com/documentation/10.0/refman/finding_multiple_solutions.html\n",
    "for sol_n in range(n_solutions):\n",
    "    MSPP_PD_ABP_pb.params.SolutionNumber = sol_n\n",
    "\n",
    "    print(f\"Solution {sol_n}:\", end=\"\")\n",
    "    obj_tot_value = 0\n",
    "    for obj_n in range(n_objectives):\n",
    "        MSPP_PD_ABP_pb.params.ObjNumber = obj_n\n",
    "        obj_tot_value = obj_tot_value + MSPP_PD_ABP_pb.ObjNWeight*MSPP_PD_ABP_pb.ObjNVal\n",
    "        print(f\" {MSPP_PD_ABP_pb.ObjNName}={MSPP_PD_ABP_pb.ObjNVal} \", end=\"|\")\n",
    "    print(f\" Weighted Total={obj_tot_value}\")\n",
    "\n",
    "    for agent in agents:\n",
    "        print(f\"Agent {agent.idx} will follow the path:\")\n",
    "        for arc in w_arcs:\n",
    "            if math.isclose(X.x[arc.idx, agent.idx], 1):\n",
    "                print(f\"{arc.i}->{arc.j}\", end=\"\\t\")\n",
    "        print()\n",
    "\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math_opt2021",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "815aa94ff997c317b35152adf27958c1441995c12fe806fd1ec102e81253708b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
